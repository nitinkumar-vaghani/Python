Here is a **clear, practical, and deeply explained** guide to **Running Async Tasks Concurrently in Python**, which is extremely important for building **FastAPI APIs, async database operations, batch processors, external API calls, background workers, and high-performance microservices.**

I will explain **all concurrency techniques** with examples:

* `asyncio.create_task()`
* `asyncio.gather()`
* `asyncio.wait()`
* `asyncio.as_completed()`
* Semaphores (limit concurrency)
* Timeouts
* Error handling
* Real-world API/database examples

By the end, you‚Äôll fully understand how Python runs tasks concurrently in async mode.

---

# üöÄ **1. The Core Problem**

You often need to run multiple tasks *together*, such as:

* making 10 API calls
* querying database for multiple users
* processing multiple files
* sending emails
* scraping websites
* doing background jobs

Synchronous code does:

```
task1 ‚Üí wait ‚Üí task2 ‚Üí wait ‚Üí task3 ‚Üí wait
```

Async concurrent code does:

```
task1 ‚Ü¥
       task2 ‚Ü¥
              task3 ‚Ü¥
```

Everything runs **at the same time**, improving performance dramatically.

---

# ‚≠ê **2. asyncio.gather() ‚Äî The Most Common Method**

`gather()` runs multiple coroutines *concurrently* and returns their results in a list.

---

## ‚úî Example 1: Run 3 tasks together

```python
import asyncio

async def work(n):
    print(f"Start {n}")
    await asyncio.sleep(1)
    print(f"End {n}")
    return n * 2

async def main():
    results = await asyncio.gather(
        work(1),
        work(2),
        work(3),
    )
    print(results)

asyncio.run(main())
```

‚è± Total time = **1 second**, not 3
üìå Output:

```
Start 1
Start 2
Start 3
End 1
End 2
End 3
[2, 4, 6]
```

---

# ‚≠ê **3. asyncio.create_task() ‚Äî Schedule tasks manually**

Use `create_task()` when you want to **start tasks immediately** and run logic while they run.

---

## ‚úî Example 2: Start tasks and continue program

```python
import asyncio

async def download(n):
    print(f"Downloading {n}")
    await asyncio.sleep(2)
    return f"Done {n}"

async def main():
    t1 = asyncio.create_task(download(1))
    t2 = asyncio.create_task(download(2))

    print("Both downloads started!")

    result1 = await t1
    result2 = await t2

    print(result1, result2)

asyncio.run(main())
```

This gives you **fine control** over each task.

---

# ‚≠ê **4. asyncio.as_completed() ‚Äî Process results as soon as they finish**

This is useful when tasks finish at different times.

---

## ‚úî Example 3: Process results in completion order

```python
import asyncio

async def job(n):
    await asyncio.sleep(n)
    return f"Finished task {n}"

async def main():
    tasks = [job(3), job(1), job(2)]

    for coro in asyncio.as_completed(tasks):
        result = await coro
        print(result)

asyncio.run(main())
```

Output (completion order):

```
Finished task 1
Finished task 2
Finished task 3
```

---

# ‚≠ê **5. asyncio.wait() ‚Äî Lower-level control**

You can wait for:

* all tasks
* first-completed
* first-exception

Example:

```python
done, pending = await asyncio.wait(tasks)
```

Rarely needed, but good to know.

---

# ‚≠ê **6. Limiting concurrency (Semaphore)**

Useful when:

* APIs block if too many requests
* DB server overload
* Avoid rate limits
* Scraping websites

---

## ‚úî Example 4: Limit concurrency to 2 at a time

```python
import asyncio

semaphore = asyncio.Semaphore(2)

async def work(n):
    async with semaphore:
        print(f"Start {n}")
        await asyncio.sleep(1)
        print(f"End {n}")

async def main():
    await asyncio.gather(*(work(i) for i in range(5)))

asyncio.run(main())
```

Even though we start 5 tasks, only **2 run at a time**.

---

# ‚≠ê **7. Timeout for async tasks**

```python
async def slow_task():
    await asyncio.sleep(5)

asyncio.wait_for(slow_task(), timeout=2)  # raises TimeoutError
```

---

# ‚≠ê **8. Running blocking (sync) code without blocking event loop**

Async code must never run CPU-heavy or blocking code.

Use:

```python
from starlette.concurrency import run_in_threadpool

result = await run_in_threadpool(blocking_function)
```

FastAPI uses this internally.

---

# ‚≠ê **9. Practical Example: Parallel API Calls**

```python
import asyncio
import httpx

async def fetch(url):
    async with httpx.AsyncClient() as client:
        res = await client.get(url)
        return res.status_code

async def main():
    urls = [
        "https://example.com",
        "https://google.com",
        "https://github.com"
    ]

    results = await asyncio.gather(*[fetch(u) for u in urls])
    print(results)

asyncio.run(main())
```

Runs all HTTP calls in parallel.

---

# ‚≠ê **10. Practical Example: Parallel Database Queries**

```python
async def get_user(id):
    return await db.fetch_one("SELECT * FROM users WHERE id = :id", {"id": id})

async def main():
    user_ids = [1, 2, 3, 4]
    users = await asyncio.gather(*(get_user(uid) for uid in user_ids))
    return users
```

Useful for analytics, aggregated APIs, etc.

---

# ‚≠ê **11. Practical Example: FastAPI Background Parallel Tasks**

```python
from fastapi import BackgroundTasks

async def send_email(email):
    await asyncio.sleep(1)
    print("Email sent to", email)

@app.post("/notify")
async def notify(background: BackgroundTasks):
    emails = ["a@x.com", "b@y.com", "c@z.com"]
    for email in emails:
        background.add_task(send_email, email)
    return {"status": "queued"}
```

---

# ‚≠ê Summary Table

| Method                  | Use Case                                       |
| ----------------------- | ---------------------------------------------- |
| `asyncio.gather()`      | Run multiple tasks concurrently & wait for all |
| `asyncio.create_task()` | Start tasks immediately, manage independently  |
| `as_completed()`        | Process tasks in completion order              |
| `asyncio.wait()`        | Lower-level waiting control                    |
| `Semaphore`             | Limit concurrency                              |
| `wait_for`              | Timeout tasks                                  |
| `run_in_threadpool`     | Run blocking sync code safely                  |

---
